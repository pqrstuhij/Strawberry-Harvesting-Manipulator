# 딸기 수확 매니퓰레이터 개발

## 프로젝트 개요

**요약 설명**: 국립 순천대학교 수직농장 환경에서 딸기를 인식·수확하는 자동화 로봇 시스템 개발. YOLO 기반 비전 인식으로 딸기 위치를 검출하고, 뎁스 정보를 활용한 매니퓰레이터 제어를 통해 수확을 수행하는 엔드-투-엔드 로봇 솔루션 구현.

- **기간**: 2025.03.11 ~ 2025.04.23
- **참여 인원**: 1명 (박상현 – 객체 인식 모델 개발 및 로봇 제어)
- **사용 기술**: Python, MoveIt, YOLO, 자사의 산업용 매니퓰레이터 Robo003, D435
- **프로젝트 목적**: 수직농장 환경에서 제한된 공간에서도 높은 생산성을 유지하며, 인구 감소로 인한 농업 노동력 부족 문제를 해결하기 위해 무인 수확 시스템 기반 자동화 로봇을 활용. 이를 통해 친환경 스마트팜을 구현하고, 노동력 의존도를 줄이며 효율적인 수확과 생산성 향상을 달성하는 것을 목표로 함.
- **결과물**: 수직농장에서 재배된 딸기를 자동으로 수확할 수 있는 모듈형 무인 스마트팜 시스템 구현

## 주요 기여 
1. YOLOv8 기반 딸기 인식 모델 개발 (robot_vision/scripts/demo.py)
- 카메라 영상에서 딸기 위치를 실시간 검출하고, 신뢰도 및 이전 좌표 필터링으로 정확도 향상
- ROS 토픽을 통해 픽셀 좌표 발행, 실시간 비전-제어 연동 구현
2. 3D 좌표 변환 및 시각화 (co_robot/scripts/roi_point_cloud.py)
- (PointCloud2)와 TF 변환으로 카메라 좌표를 실제 로봇 기준 3D 좌표로 변환
- RViz Marker를 활용해 대상물 위치를 확인
3. TCP 기반 실제 로봇 제어 (co_robot/scripts/tcp_srv.py)
- 실제 로봇(TCP 서버)과 통신하여 좌표 기반 이동 명령 전송
- ROS 서비스(vision_robot) 연동으로 자동 수확 동작 구현
- 이전 좌표 및 작업 영역 검증을 통해 안전하고 안정적인 로봇 제어 확보
4. End-to-End 통합 무인 수확 시스템 구현
- 비전 모델, 3D 좌표 처리, TCP 통신, 로봇 제어를 통합하여 무인 수확 시스템 완성
- ROS 콜백 및 서비스 기반 실시간 처리로 안정적 운영 환경 구축


## 문재 해결

- **문제 1: 중복 객체 검출 및 명령 발행 문제**\
 YOLOv8이 연속적으로 동일 딸기를 검출하며 불필요한 명령이 로봇에 전송되어 동작 불안정 발생.\
  **해결**: 전 발행 좌표와 최소 거리(min_distance=20px), 발행 최소 간격(publish_interval=10s) 조건 적용 및 랜덤 선택 알고리즘으로 명령 발행 최적화, 로봇 동작 안정성 향상.

- **문제 2: 2D 이미지 좌표와 3D 좌표 불일치**\
  RGB 카메라 픽셀 좌표와 Depth 카메라 3D 좌표 간 정확한 매칭 어려움.\
  **해결**: TF 변환(/camera_link1 → /base)과 PointCloud2 데이터 활용하여 카메라 좌표계 → 로봇 기준 좌표계로 변환. 3D 좌표 정확도 ±2cm 확보.

- **문제 3: 로봇-비전 시스템 동기화 문제**\
  비전 처리 속도가 로봇 동작 속도를 앞서면서 명령 유실 발생.\
  **해결**: awaiting_100 플래그와 서비스 응답 기반 동기화 구현, 작업 완료 후에만 다음 명령 처리. 명령 유실 제로, 시스템 완전 동기화 달성.

- **문제 4: 로봇 안전성 문제**\
  반복 좌표 전송, 작업 영역 이탈, 무의미 명령 전송 등 안전 위험 존재.\
  **해결**: 이전 좌표 대비 50mm 미만 차이는 명령 무시, X축 허용 범위(298–590) 설정, (0,0,0) 좌표 필터링. 비정상 명령 차단, 시스템 안전성 향상.

- **문제 5: 실시간 처리 지연 문제**\
  YOLO 추론, PointCloud 처리, TCP 통신 등 다중 프로세스로 인해 전체 파이프라인 지연 발생.\
  **해결**: ROS 노드 분리, 비동기 TCP 통신, 경량 YOLOv8-n 모델 적용. 전체 파이프라인 200ms 내 처리 달성.

- **문제 6: 실제 환경 적용 문제**\
  조명, 배경, 딸기 배열 차이로 실험실 모델 그대로 적용 어려움.\
  **해결**: 다양한 환경 및 실제 수직농장 모듈에서 확보한 데이터셋으로 학습, conf_threshold=0.6 설정, OpenCV 실시간 디버깅 시각화 적용. 실제 환경에서 90% 이상 검출 정확도 달성.


## 기술 스택

| **카테고리** | **기술** |
| --- | --- |
| 프로그래밍 | Python |
| 프레임워크 | ROS1, MoveIt, YOLO |
| 하드웨어 | (자사 매니퓰레이터)Robo003, 뎁스 카메라 D435 |
| 통신 | ROS1 Topic/Service, TCP/IP 소켓 (Robo003) |
| 도구 | Git, RViz |

## 프로젝트 성과

- **분류 및 수확 성과**: 딸기 인식 후 수확 성공률 90% 이상, 워크스페이스 벗어나는 대상은 수확하지 않음.
- **기술적 기여**: YOLOv8 기반 실시간 딸기 인식, 2D→3D 좌표 변환, ROS 서비스와 TCP/IP 기반 로봇 제어 구현.
- **시연 성공**: 수직농장 환경에서 안정적 무인 수확 시스템 시연 완료.

## 데모 및 시각 자료


https://github.com/user-attachments/assets/b516a10d-d532-49b8-860f-105b28e46399


https://github.com/user-attachments/assets/cd9681e0-2c7b-4204-9c4b-1ce51b37bcae


- **로봇 구동**: 초기 대기 포즈 진입 **→** 카메라로 딸기 인식 **→** 바운딩 박스 중심 픽셀 좌표를 /detected_objects 토픽으로 발행 **→** PointCloud에서 3D 좌표 추출 **→** TF 변환으로 로봇 기준 좌표 계산 **→** vision_robot 서비스 호출 **→** TCP/IP로 로봇 제어기 명령 전송 **→** 로봇 수확 완료 응답 수신 **→** 다시 대기 포즈로 복귀 (사이클 반복)

- **시스템 아키텍처 **
![딸기](https://github.com/user-attachments/assets/5e37b67e-5bdb-4141-a130-b48265a8b3a9)





## 연락처

- **이메일**: jacob7575@senestechnology.com
- **GitHub**: github.com/pqrstuhij

본 프로젝트는 자사의 산업용 매니퓰레이터(Robo003)을 사용하여 ROS 1, YOLOv8, TCP/IP 통신을 활용한 딸기 무인 수확 로봇 시스템 구현 프로젝트입니다. 전체 시스템을 직접 개발하고, 실제 로봇과 연동하여 End-to-End 자동화 및 실시간 수확 검증을 수행했습니다.
